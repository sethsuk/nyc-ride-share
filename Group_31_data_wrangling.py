# -*- coding: utf-8 -*-
"""CIS 5500 Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aRtN33nG3BwdPrJ3oHkmHUE7siP7JltJ
"""

!pip install sqlalchemy psycopg2-binary

import pandas as pd
import kagglehub
from kagglehub import KaggleDatasetAdapter

# from sqlalchemy import create_engine

"""# Uber NYC Dataset"""

file_list = ["fhvhv_tripdata_2021-01.parquet"] # change to appropriate month

df_list = []

for file_name in file_list:
  df_list.append(
    kagglehub.load_dataset(
      KaggleDatasetAdapter.PANDAS,
      "shuhengmo/uber-nyc-forhire-vehicles-trip-data-2021",
      file_name,
    )
  )

uber_df = pd.concat(df_list)

# # Load the latest version
# df = kagglehub.load_dataset(
#   KaggleDatasetAdapter.PANDAS,
#   "shuhengmo/uber-nyc-forhire-vehicles-trip-data-2021",
#   file_path,
#   # Provide any additional arguments like
#   # sql_query or pandas_kwargs. See the
#   # documenation for more information:
#   # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas
# )

# print("First 5 records:", df.head())

uber_df.head()

uber_df.shape

# uber_df[['request_datetime', 'pickup_datetime', 'dropoff_datetime', 'dropoff_datetime', 'trip_miles', 'trip_time', 'base_passenger_fare', 'tips']].describe()

uber_df.dtypes

# isolate only Uber rides
uber_df = uber_df[uber_df['hvfhs_license_num'] == 'HV0003']

# request hour floor used to merge with weather_df
uber_df['request_hour'] = uber_df['request_datetime'].dt.floor('H')

# replace null airport fee with 0
uber_df['airport_fee'].fillna(0, inplace=True)

# calculate total_fare excluding tolls and tips
uber_df['total_fare'] = uber_df['base_passenger_fare'] + uber_df['sales_tax'] + uber_df['congestion_surcharge'] + uber_df['airport_fee']

# isolate specific columns of interest
uber_df = uber_df[['tolls', 'trip_miles', 'PULocationID', 'trip_time', 'on_scene_datetime', 'request_datetime', 'DOLocationID', 'driver_pay', 'tips', 'total_fare', 'request_hour']]

uber_df = uber_df.reset_index(drop=True)
uber_df['ride_id'] = uber_df.index + 1

uber_df.isnull().any()

uber_df

from google.colab import files

uber_df.to_csv('uber_rides_dec.csv', index=False)

files.download('uber_rides_dec.csv')

# DB_HOST = 'nyc-ride-share.cr1qs8bpfelg.us-east-1.rds.amazonaws.com'
# DB_USER = 'postgres'
# DB_PW = 'qEVEuU44rN6snSdQId6c'
# DB_PORT = '5432'
# DB_NAME = 'uber_ride_share'

# engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PW}@{DB_HOST}:{DB_PORT}/{DB_NAME}')

# chunk_size = 100000

# uber_df.iloc[:chunk_size].to_sql('uber_rides', engine, if_exists='replace', index=False)

# for i in range(chunk_size, len(uber_df), chunk_size):
#     chunk = uber_df.iloc[i:i+chunk_size]
#     chunk.to_sql('uber_rides', engine, if_exists='append', index=False)

"""# NYC Weather Dataset"""

weather_df = pd.read_csv('weather_data.csv')
weather_df.head()

weather_df.dtypes

weather_df.shape

weather_df.isnull().any()

# weather_df.describe()

weather_df['time'] = pd.to_datetime(weather_df['time'])

weather_df = weather_df.drop(columns=['wind_gusts_10m (km/h)'])

weather_df = weather_df.rename(columns={
    'temperature_2m (°C)': 'temperature',
    'apparent_temperature (°C)': 'apparent_temperature',
    'precipitation (mm)': 'precipitation',
    'rain (mm)': 'rain',
    'snowfall (cm)': 'snowfall',
    'snow_depth (m)': 'snow_depth',
    'wind_speed_10m (km/h)': 'wind_speed'
})

weather_df.head()

from google.colab import files

weather_df.to_csv('weather_cleaned.csv', index=False)

files.download('weather_cleaned.csv')

"""# Merge Dataframes"""

merged_df = pd.merge(uber_df, weather_df, left_on='request_hour', right_on='time')

merged_df = merged_df.drop(columns=['time'])

merged_df

merged_df.dtypes

merged_df.shape

merged_df.isnull().any()

null_mask = merged_df.isnull().any(axis=1)
null_rows_df = merged_df[null_mask]

null_rows_df